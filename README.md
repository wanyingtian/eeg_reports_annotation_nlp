# LLM-Based Clinical Report Analysis

This project analyzes clinical EEG reports using a combination of traditional machine learning models and LLMs like Mistral via `llama.cpp`. The pipeline processes text data, runs multiple classification models, evaluates performance, and analyzes supporting evidence.

## Project Structure

```
.
â”œâ”€â”€ data/                       # Raw data (e.g., SQLite .db file)
â”‚   â””â”€â”€ zoe_reports_10.db

â”œâ”€â”€ environment.yml            # Conda environment file (Python + NLP tools)

â”œâ”€â”€ outputs/                   # Output artifacts and intermediate results
â”‚   â”œâ”€â”€ baseline_results/      # ML model outputs
â”‚   â”‚   â”œâ”€â”€ inference_results/
â”‚   â”‚   â”œâ”€â”€ trained_models/
â”‚   â”‚   â””â”€â”€ training_results/
â”‚   â”œâ”€â”€ evidence_analysis_results/   # Polarity classification output
â”‚   â”œâ”€â”€ performance_plots/           # Visualization results (bar charts, etc.)
â”‚   â”œâ”€â”€ pipeline_output/             # Output from LLM pipeline
â”‚   â”‚   â”œâ”€â”€ mistral_zoe_config_*.txt
â”‚   â”‚   â””â”€â”€ mistral_zoe_first_10_results_*.csv
â”‚   â””â”€â”€ processed_output/            # Final processed results

â””â”€â”€ src/                      # Source code
    â”œâ”€â”€ baseline_models/      # BoW + LR and SHAP explanation scripts
    â”‚   â”œâ”€â”€ train.py
    â”‚   â”œâ”€â”€ inference.py
    â”‚   â””â”€â”€ shap_explanations.ipynb
    â”œâ”€â”€ evidence_analysis/    # Rule-based and model-based polarity classification
    â”‚   â””â”€â”€ evidence_polarity_classification.py
    â”œâ”€â”€ LLM_pipeline/         # LLM-based classification and grammar-based parsing
    â”‚   â”œâ”€â”€ pipeline.py
    â”‚   â”œâ”€â”€ process_output.py
    â”‚   â”œâ”€â”€ result_grammar.gbnf
    â”‚   â””â”€â”€ result_grammar_test.gbnf
    â””â”€â”€ performance_analysis/ # Accuracy, agreement metrics, visualization
        â”œâ”€â”€ main.py
        â”œâ”€â”€ analysis_functions.py
        â”œâ”€â”€ result_preprocessing.py
        â””â”€â”€ plotting.py
```

## Installation

Ensure you have [conda](https://docs.conda.io/en/latest/) installed. Then create the environment:

```bash
conda env create -f environment.yml
conda activate llama_grammar
```

If you encounter dependency resolution issues (slow install or solver errors), consider installing [**Mamba**](https://mamba.readthedocs.io/en/latest/installation.html) for faster and more robust environment solving:

```bash
conda install -n base -c conda-forge mamba
```

Then use:

```bash
mamba env create -f environment.yml
```

## Usage

### 1. Run the LLM pipeline

If your machine has GPU, make sure to install llama_cpp with GPU support:
```bash
CUDACXX=/usr/local/cuda/bin/nvcc CMAKE_ARGS="-DLLAMA_CUDA=on" FORCE_CMAKE=1 pip install llama-cpp-python
```
Then check the current GPU status using NVIDIAâ€™s System Management Interface
```bash
nvidia-smi
```

If your machine has CPU only, ignore the previous step.
To run the pipeline:
```bash
python src/LLM_pipeline/pipeline.py --num_reports 10 --author zoe --model mistral 
```

### 2. Process LLM output
```bash
python src/LLM_pipeline/process_output.py mistral_zoe_first_10_results_v1.csv
```

### 3. Train and evaluate baseline models
```bash
python src/baseline_models/train.py
```
(input baseline model when prompted: bag_of_words or bert_base)

```bash
python src/baseline_models/inference.py --model bert_base
python src/baseline_models/inference.py --model bag_of_words
```

### 4. Analyze evidence polarity
```bash
python src/evidence_analysis/evidence_polarity_classification.py
```

### 5. Generate plots and evaluation results
```bash
python src/performance_analysis/main.py
```

## Features

- BoW + Logistic Regression baseline
- Sentence-transformer and transformer-based pipelines
- LLM grammar-based parsing via `llama-cpp-python`
- SHAP explanation integration
- Rule-based and model-based evidence polarity classification
- Performance visualization

## ðŸ§  Requirements

- Python 3.12
- `llama-cpp-python` (for running GGUF models)
- `sentence-transformers`, `transformers`, `torch`
- `pandas`, `scikit-learn`, `matplotlib`, etc.

See `environment.yml` for full list.

## ðŸ“¬ Contact

If you use or modify this code, feel free to reach out or submit improvements via pull request.
